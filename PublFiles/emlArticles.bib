@comment{{This file has been generated by bib2bib 1.98}}

@comment{{Command line: /usr/bin/bib2bib -q -c '$type = "article"' /data/PublFiles/eml.bib}}

@article{bellman:2020a,
  author = {Kerstin Bellman and Nikil Dutt and Lukas Esterle and
		  Andreas Herkersdorf and Axel Jantsch and C. Landauer and P.
		  R. Lewis and M. Platzner and N. TaheriNejad and K.
		  Tammem\"{a}e},
  journal = {ACM Transactions on Cyber-Physical Systems},
  title = {Self-aware Cyber-Physical Systems},
  year = 2020,
  key = {selfaware,eml},
  pages = {1-24},
  address = {New York, NY, USA},
  volume = {4},
  number = {4},
  issn = {2378-962X},
  url = {https://doi.org/10.1145/3375716},
  doi = {10.1145/3375716},
  abstract = {In this article, we make the case for the new class of
		  Self-aware Cyber-physical Systems. By bringing together the
		  two established fields of cyber-physical systems and
		  self-aware computing, we aim at creating systems with
		  strongly increased yet managed autonomy, which is a main
		  requirement for many emerging and future applications and
		  technologies. Self-aware cyber-physical systems are
		  situated in a physical environment and constrained in their
		  resources, and they understand their own state and
		  environment and, based on that understanding, are able to
		  make decisions autonomously at runtime in a
		  self-explanatory way. In an attempt to lay out a research
		  agenda, we bring up and elaborate on five key challenges
		  for future self-aware cyber-physical systems: (i) How can
		  we build resource-sensitive yet self-aware systems? (ii)
		  How to acknowledge situatedness and subjectivity? (iii)
		  What are effective infrastructures for implementing
		  self-awareness processes? (iv) How can we verify self-aware
		  cyber-physical systems and, in particular, which guarantees
		  can we give? (v) What novel development processes will be
		  required to engineer self-aware cyber-physical systems? We
		  review each of these challenges in some detail and
		  emphasize that addressing all of them requires the system
		  to make a comprehensive assessment of the situation and a
		  continual introspection of its own state to sensibly
		  balance diverse requirements, constraints, short-term and
		  long-term objectives. Throughout, we draw on three examples
		  of cyber-physical systems that may benefit from
		  self-awareness: a multi-processor system-on-chip, a Mars
		  rover, and an implanted insulin pump. These three very
		  different systems nevertheless have similar
		  characteristics: limited resources, complex unforeseeable
		  environmental dynamics, high expectations on their
		  reliability, and substantial levels of risk associated with
		  malfunctioning. Using these examples, we discuss the
		  potential role of self-awareness in both highly complex and
		  rather more simple systems, and as a main conclusion we
		  highlight the need for research on above listed topics.},
  month = {June},
  articleno = {38},
  numpages = {26},
  keywords = {Self-awareness, guarantees, development processes,
		  verification, subjectivity, situatedness,
		  resource-sensitive, organizational infrastructure,
		  cyber-physical systems}
}

@article{hoffmann:2020a,
  author = {Henrik {Hoffmann} and Axel {Jantsch} and Nikil D. {Dutt}},
  journal = {Proceedings of the IEEE},
  title = {Embodied Self-Aware Computing Systems},
  year = 2020,
  pages = {1-20},
  key = {selfaware,eml},
  keywords = {Control;embedded systems (ESs);machine learning
		  (ML);self-aware computing.},
  doi = {10.1109/JPROC.2020.2977054},
  issn = {1558-2256},
  url = {http://jantsch.se/AxelJantsch/papers/2020/HankHoffmann-IEEEProceedings.pdf}
}

@article{taherinejad:2020a,
  author = {N. {TaheriNejad} and A. {Herkersdorf} and A. {Jantsch}},
  journal = {IEEE Design Test},
  title = {Autonomous Systems, Trust and Guarantees},
  year = 2020,
  issn = {2168-2356},
  doi = { 10.1109/MDAT.2020.3024145},
  url = {http://jantsch.se/AxelJantsch/papers/2020/NimaTaherinejad-DesignAndTest.pdf},
  key = {selfaware,eml},
  pages = {1-1}
}

@article{wess:2021,
  author = {M. {Wess} and M. {Ivanov} and C. {Unger} and A. {Nookala} and A. {Wendt} and A. {Jantsch}},
  journal = {IEEE Access},
  title = {ANNETTE: Accurate Neural Network Execution Time Estimation With Stacked Models},
  year = {2021},
  volume = {9},
  number = {},
  pages = {3545-3556},
  abstract = {With new accelerator hardware for Deep Neural Networks (DNNs), the computing power for Artificial Intelligence (AI) applications has increased rapidly. However, as DNN algorithms become more complex and optimized for specific applications, latency requirements remain challenging, and it is critical to find the optimal points in the design space. To decouple the architectural search from the target hardware, we propose a time estimation framework that allows for modeling the inference latency of DNNs on hardware accelerators based on mapping and layer-wise estimation models. The proposed methodology extracts a set of models from micro-kernel and multi-layer benchmarks and generates a stacked model for mapping and network execution time estimation. We compare estimation accuracy and fidelity of the generated mixed models, statistical models with the roofline model, and a refined roofline model for evaluation. We test the mixed models on the ZCU102 SoC board with Xilinx Deep Neural Network Development Kit (DNNDK) and Intel Neural Compute Stick 2 (NCS2) on a set of 12 state-of-the-art neural networks. It shows an average estimation error of 3.47% for the DNNDK and 7.44% for the NCS2, outperforming the statistical and analytical layer models for almost all selected networks. For a randomly selected subset of 34 networks of the NASBench dataset, the mixed model reaches fidelity of 0.988 in Spearmanâ€™s  $\rho $  rank correlation coefficient metric.},
  keywords = {Hardware;Computational modeling;Estimation;Benchmark testing;Biological system modeling;Computer architecture;Tools;Analytical models;estimation;neural network hardware},
  doi = {10.1109/ACCESS.2020.3047259},
  issn = {2169-3536},
  month = {}
}

